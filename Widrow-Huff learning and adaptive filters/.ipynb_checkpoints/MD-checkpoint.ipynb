{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Widrow-Huff learning and adaptive filters\n",
    "----\n",
    "\n",
    "[image01]: ./screenshots/MSE.JPG \"MSE\"\n",
    "[image02]: ./screenshots/SoftMax.JPG \"SoftMax\"\n",
    "\n",
    "Assignment 03 (Due date: Oct. 8, 2017)\n",
    "Neural Networks\n",
    "Assignment 03\n",
    "Due: Oct. 8, 2017\n",
    " \n",
    "### Problem Statement\n",
    "---\n",
    "- The purpose of the this assignment is to practice with Widrow-Huff learning and adaptive filters.\n",
    "- Write a program to predict the price and the volume of a stock by using the Adaptive filter ADALINE.\n",
    "\n",
    " \n",
    "  **Sliders:**\n",
    "      1] Number of Delayed Elements: This slider selects number of delayed elements for each input (price, volume). Range: 0 to 100 default: 10.\n",
    "      2] Learning Rate: Adjust the learning rate. Range should be between 0.001 and 1.0. Default value = 0.1\n",
    "      3] Training Sample Size (Percentage): This slider allows the user to select the percentage of the samples to be used for training. range 0% to 100%. Default value should be 80% which means 80% of the samples should be used for training and the other 20% should be used for error calculation.\n",
    "      4] Batch Size:  This slider selects the batch size. Range  1 to 200. Default 100.\n",
    "      5] Number of Iterations: This slider allows the user to change the number of times that the system goes over all the training samples. Range 1 to 100. Default: 10\n",
    "\n",
    "\n",
    "  **Buttons:**\n",
    "      1] Set Weights to Zero: When this button is pushed all the weights and biases should be set to zero.\n",
    "      2] Adjust Weights: \n",
    "           - When this button is pressed the LMS algorithm should be applied and plots should be displayed. \n",
    "           - Your program should display four plots, Mean Squared Error (MSE) and Maximum Absolute Error (MAE) for price and volume. Calculations of the error should be done after the \"Batch Size\" samples have been processed. In other words, go through the current training batch and adjust the weight accordingly. Once that batch is processed, freeze the weights and biases, run the test set through the network and display MSE and MAE for price and volume. Notice that you will end up with four plots. The limits of the error axes should be set between 0 and 2.  \n",
    "Notes:\n",
    "When your program is started it should automatically read the input data file. Normalize the price and volume data by dividing each of the values by the maximum value of the corresponding data and then subtracting 0.5 from each value.\n",
    "Your neural network should have two nodes (Price, Volume).\n",
    "The number of inputs to each of these nodes depends on the \"Number of Delayed Elements\"\n",
    "The weights should not be reset when the \"Learn\" button is pressed.\n",
    "Make sure that you follow the submission guidelines to submit your code to Blackboard\n",
    "You should include the data file as part of your submission.\n",
    "You may use TensorFlow for this assignment if you wish.\n",
    " \n",
    "Clarification:\n",
    "If the \"Number of Delayed Elements\" is equal to 7 then your network will have 16 input values and two outputs (one current price and 7 previous prices plus one current volume and 7 previous volumes).\n",
    "Assuming that the total number of samples in the input file is 2000 and Training Sample Size (Percentage)  = 50% , then the number of training samples will be equal to 1000. Assuming \"Batch Size\"=200, and the  \"Number of Iterations\"=6 ; Then you should select the first 1000 samples as training and use the rest of the samples as test. After processing every 200 training samples, you should calculate the mean and max error for price and volume (using the test samples). You should go over the 1000 training samples 6 times. In other words it will take 5 batches to go over the entire training samples, and you should go over the entire training samples 6 times (30 batches should be processed).\n",
    "data\n",
    "Code to read data and convert it to a vector\n",
    " \n",
    "### Results \n",
    "---\n",
    "- I have created a gui using tkinter to demo MSE error graph and Softmax error graph\n",
    "- I have used tensorflow for mnist classification\n",
    "- To run the program you clone the repository\n",
    "- run **`Shah_01_01.py`** file which will create the gui\n",
    "- Below is the sceenshot of the gui\n",
    "\n",
    "### Screenshot for MEAN SQUARE ERROR \n",
    "---\n",
    "![SCREEENSHOT][image01]\n",
    "\n",
    "### Screenshot for SOFTMAX\n",
    "---\n",
    "![SCREEENSHOT][image02]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
