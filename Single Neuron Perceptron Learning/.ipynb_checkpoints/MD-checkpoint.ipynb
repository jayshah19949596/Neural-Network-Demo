{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## single neuron decision boundary and Perceptron learning rule\n",
    "----\n",
    "\n",
    "[image01]: ./screenshots/screenshot_1.JPG \"screenshot\"\n",
    "[image02]: ./screenshots/screenshot_2.JPG \"screenshot\"\n",
    "[image03]: ./screenshots/screenshot_3.JPG \"screenshot\"\n",
    "\n",
    "\n",
    "Assignment 01 (Due date: Sept. 17, 2017)\n",
    "Neural Networks\n",
    "Assignment 01\n",
    "Due date: Sept. 17, 2017\n",
    " \n",
    "### Problem Statement\n",
    "---\n",
    "- The purpose of the this assignment is to practice with Hebbian learning rules.\n",
    "- Write a program to implement a single layer neural network with 10 nodes.\n",
    "- Your program should include 1 sliders, 2 buttons, and 2 drop-down selection box.\n",
    "- Slider:\n",
    "      1] \"alpha (learning rate)\". Range should be between 0.001 and 1.0. Default value = 0.1\n",
    "      2] Buttons:\n",
    "          a)\"Adjust Weights (Learn)\". When this button is pressed the selected Hebbian learning rule should  be applied for 100 epochs.\n",
    "          b)\"Rondomize Weights\". When this button is pressed weights and biases should be randomized. The value of the randomized weights and biases should be from -0.001 to 0.001 .\n",
    " \n",
    "- Drop-Down Selection Boxes\n",
    "      1] \"Select Learning Method\". A drop-down box to select one of the three Hebbian rules from your textbook, i.e. \"Filtered Learning\", \"Delta Rule\", or \"Unsupervised Hebb\".\n",
    "      2] \"Transfer Functions\". A drop-down box to allow the user to select between three transfer functions (Symmetrical Hard limit, Hyperbolic Tangent, and Linear)\n",
    "\n",
    "- Notes:\n",
    "  - Put all the mnist image files in a directory called \"Data\". This directory should be located in the same folder as your main program. When submitting your assignment you do not need to submit the mnist images.\n",
    "  - When your program starts it should automatically read the mnist data. Once the mnist data is read your program should convert each image to a vector and normalize each vector element to be in the range of -1 to 1. i.e. , divide the input numbers by 127.5 and subtract 1.0. Notice that normalizing each element of a vector to be between -1 to 1 does not normalize the vector itself.\n",
    "  - When your program starts it should automatically initialize all the weights and biases to be from -0.001 to 0.001\n",
    "Separate the input data into two sets. The first set should include 80% of your data set (randomly selected). This is your training set. \n",
    "  - The second set (the other 20%) is the test set. The test set will be used for calculating the error rate.\n",
    "  - The index of the maximum value of the output vector is selected as the class id.\n",
    "  - Plot the error rate, in percent, after each epoch on the error rate graph. An epoch is one pass over all the training samples. \n",
    "  - This means that you train (adjust the weights) for one complete set of the training data (one epoch). Then turn off the training (freeze the weights and biases) and run the test data through the network and calculate the error rate\n",
    "  - The error-rate graph should be able to display up to 1000 epochs.\n",
    "  - If you are using python, your assignment should run on Python 3.x\n",
    "  - Make sure that you follow the submission guidelines to submit your code to Blackboard.\n",
    " \n",
    " \n",
    "### Results \n",
    "---\n",
    "\n",
    "- I have created a gui using tkinter to demo hebbian learning rule error graph\n",
    "- To run the program you clone the repository\n",
    "- run **`Shah_02_01.py`** file which will create the gui\n",
    "- Below is the sceenshot of the gui\n",
    "\n",
    "\n",
    "![SCREEENSHOT][image01]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
